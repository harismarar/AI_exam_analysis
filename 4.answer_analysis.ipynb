{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba60283-bd8c-40aa-b0c7-8547c8db24f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting audio transcripts into text ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 5.7: 100%|█████████████████████████████████████████████████| 225M/225M [00:37<00:00, 6.01MB/s]\n",
      "Unzipping C:\\Users\\haris\\AppData\\Local\\Temp\\tmpwrlumrvo.zip to C:\\Users\\haris\\.cache\\language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-5.7.zip to C:\\Users\\haris\\.cache\\language_tool_python.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score: 32.71764705882353\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import language_tool_python\n",
    "\n",
    "supervised_learning = \"Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset, meaning that the input data is paired with corresponding output labels. The goal of supervised learning is to learn a mapping function from the input variables to the output variables, based on the labeled examples provided during training. In other words, the algorithm learns to make predictions or decisions by generalizing patterns from the labeled training data.Examples of supervised learning include image classification, spam email detection, handwriting recognition, speech recognition, predicting stock prices, language translation, medical diagnosis, customer churn prediction, autonomous vehicles, and credit scoring.\"\n",
    "unsupervised_learning = \"Unsupervised learning is a machine learning paradigm where the algorithm is trained on unlabeled data, and the objective is to discover inherent patterns or structures within the data without explicit guidance. In unsupervised learning, the algorithm explores the data's inherent structure, often through clustering or dimensionality reduction techniques. Examples of unsupervised learning include clustering similar documents in a large corpus, anomaly detection to identify unusual patterns, dimensionality reduction for feature extraction, topic modeling to discover themes in text data, and generative modeling for creating new data instances based on the learned patterns\"\n",
    "reinforcement_learning = \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions. The goal is for the agent to learn a policy that maximizes the cumulative reward over time.\"\n",
    "overfitting = \"Overfitting occurs when a machine learning model learns the training data too well, including its noise and outliers, leading to poor generalization on new, unseen data. It often results from models being too complex relative to the amount of training data. To address overfitting, techniques such as regularization, reducing model complexity, increasing the size of the training dataset, and using cross-validation to evaluate model performance on different subsets of data can be employed\"\n",
    "cross_validation = \"Cross-validation is a technique used to assess a model's performance by partitioning the dataset into multiple subsets. The model is trained on some subsets and tested on others, allowing for a more robust evaluation. Common methods include k-fold cross-validation, where the data is divided into k subsets, and the model is trained and tested k times, each time using a different subset for testing.\"\n",
    "bias_variance_tradeoff = \"The bias-variance tradeoff is a fundamental concept in machine learning that deals with finding the right level of model complexity. High bias (underfitting) occurs when a model is too simple and cannot capture the underlying patterns in the data. High variance (overfitting) occurs when a model is too complex and fits the training data too closely, failing to generalize well to new data. Balancing bias and variance is crucial for building models that perform well on diverse datasets. Regularization techniques and model selection are commonly used to manage the bias-variance tradeoff\"\n",
    "\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "  \"\"\"\n",
    "  Opens and listens to an audio file and translates it to text\n",
    "  Args: audio file\n",
    "  Returns: text of transcribed audio file\n",
    "  \"\"\"\n",
    "  with sr.AudioFile(audio_file) as source:\n",
    "    audio_text = r.listen(source)\n",
    "    try:\n",
    "        text = r.recognize_google(audio_text)\n",
    "        print('Converting audio transcripts into text ...')\n",
    "        # print(text)\n",
    "    except:\n",
    "         print('Sorry.. run again...')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "def extract_keywords(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    keywords = [token.text for token in doc if token.is_alpha]\n",
    "    return keywords\n",
    "\n",
    "\n",
    "\n",
    "def check_semantic(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Example: Check for specific semantic elements like named entities\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "\n",
    "    # You can also use dependency parsing to analyze sentence structure\n",
    "    # For example, check if certain words are connected in a specific way\n",
    "    root_verb = [token.text for token in doc if token.dep_ == 'ROOT' and token.pos_ == 'VERB']\n",
    "\n",
    "    # Example custom scoring function: Assign a score based on the number of entities\n",
    "    # and the presence of a root verb\n",
    "    semantic_score = calculate_semantic_score(entities, root_verb)\n",
    "\n",
    "    return semantic_score\n",
    "\n",
    "\n",
    "\n",
    "def calculate_semantic_score(entities, root_verb):\n",
    "    # Example: Assign a higher score if entities and a root verb are present\n",
    "    score = 0\n",
    "    if entities:\n",
    "        score += 0.5\n",
    "    if root_verb:\n",
    "        score += 0.5\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def check_syntax(text):\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    matches = tool.check(text)\n",
    "\n",
    "    # Count the number of matches\n",
    "    num_matches = len(matches)\n",
    "\n",
    "    # Assign a score based on the number of matches\n",
    "    # You can customize this scoring logic based on your requirements\n",
    "    score = (1 - (num_matches*0.035))  # For example, inverse of the number of matches\n",
    "\n",
    "    return score, matches\n",
    "\n",
    "\n",
    "\n",
    "def score_answer(chosen_number, keywords):\n",
    "    correct_answers = [\n",
    "        \"Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset, meaning that the input data is paired with corresponding output labels. The goal of supervised learning is to learn a mapping function from the input variables to the output variables, based on the labeled examples provided during training. In other words, the algorithm learns to make predictions or decisions by generalizing patterns from the labeled training data.Examples of supervised learning include image classification, spam email detection, handwriting recognition, speech recognition, predicting stock prices, language translation, medical diagnosis, customer churn prediction, autonomous vehicles, and credit scoring.\",\n",
    "        \"Unsupervised learning is a machine learning paradigm where the algorithm is trained on unlabeled data, and the objective is to discover inherent patterns or structures within the data without explicit guidance. In unsupervised learning, the algorithm explores the data's inherent structure, often through clustering or dimensionality reduction techniques. Examples of unsupervised learning include clustering similar documents in a large corpus, anomaly detection to identify unusual patterns, dimensionality reduction for feature extraction, topic modeling to discover themes in text data, and generative modeling for creating new data instances based on the learned patterns\",\n",
    "        \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions. The goal is for the agent to learn a policy that maximizes the cumulative reward over time.\",\n",
    "        \"Overfitting occurs when a machine learning model learns the training data too well, including its noise and outliers, leading to poor generalization on new, unseen data. It often results from models being too complex relative to the amount of training data. To address overfitting, techniques such as regularization, reducing model complexity, increasing the size of the training dataset, and using cross-validation to evaluate model performance on different subsets of data can be employed\",\n",
    "        \"Cross-validation is a technique used to assess a model's performance by partitioning the dataset into multiple subsets. The model is trained on some subsets and tested on others, allowing for a more robust evaluation. Common methods include k-fold cross-validation, where the data is divided into k subsets, and the model is trained and tested k times, each time using a different subset for testing.\",\n",
    "        \"The bias-variance tradeoff is a fundamental concept in machine learning that deals with finding the right level of model complexity. High bias (underfitting) occurs when a model is too simple and cannot capture the underlying patterns in the data. High variance (overfitting) occurs when a model is too complex and fits the training data too closely, failing to generalize well to new data. Balancing bias and variance is crucial for building models that perform well on diverse datasets. Regularization techniques and model selection are commonly used to manage the bias-variance tradeoff\"\n",
    "    ]\n",
    "\n",
    "    correct_answer = correct_answers[chosen_number - 1]  # Adjust for 0-based index\n",
    "\n",
    "    keyword_match = set(keywords) & set(correct_answer.split())\n",
    "    keyword_score = len(keyword_match) / len(correct_answer.split()) * 100\n",
    "    return keyword_score\n",
    "\n",
    "\n",
    "def calculate_scores(semantic, syntax, answer):\n",
    "    total_score = 0.2 * semantic + 0.2 * syntax + 0.6 * answer\n",
    "    return total_score\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_student_answer(audio_path, chosen_number):\n",
    "    # Assuming correct_answer_keywords is a list of keywords related to the correct answer\n",
    "    correct_answer_keywords = get_correct_answer_keywords(chosen_number)\n",
    "    # Rest of the code remains the same\n",
    "    text = speech_to_text(audio_path)\n",
    "    keywords = extract_keywords(text)\n",
    "    syntax_matches = check_syntax(text)\n",
    "    semantic_score = check_semantic(text)\n",
    "    answer_score = score_answer(chosen_number, keywords)  # Fix here\n",
    "    syntax_score = 100 - (len(syntax_matches) * 3.5)  # Adjust as needed\n",
    "    final_score = calculate_scores(semantic_score, syntax_score, answer_score)\n",
    "\n",
    "    return final_score\n",
    "\n",
    "def get_correct_answer_keywords(chosen_number):\n",
    "    # Assuming chosen_number is between 1 and 6\n",
    "    chosen_index = chosen_number - 1\n",
    "    correct_answers = [\n",
    "        \"Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset, meaning that the input data is paired with corresponding output labels. The goal of supervised learning is to learn a mapping function from the input variables to the output variables, based on the labeled examples provided during training. In other words, the algorithm learns to make predictions or decisions by generalizing patterns from the labeled training data.Examples of supervised learning include image classification, spam email detection, handwriting recognition, speech recognition, predicting stock prices, language translation, medical diagnosis, customer churn prediction, autonomous vehicles, and credit scoring.\",\n",
    "        \"Unsupervised learning is a machine learning paradigm where the algorithm is trained on unlabeled data, and the objective is to discover inherent patterns or structures within the data without explicit guidance. In unsupervised learning, the algorithm explores the data's inherent structure, often through clustering or dimensionality reduction techniques. Examples of unsupervised learning include clustering similar documents in a large corpus, anomaly detection to identify unusual patterns, dimensionality reduction for feature extraction, topic modeling to discover themes in text data, and generative modeling for creating new data instances based on the learned patterns\",\n",
    "        \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions. The goal is for the agent to learn a policy that maximizes the cumulative reward over time.\",\n",
    "        \"Overfitting occurs when a machine learning model learns the training data too well, including its noise and outliers, leading to poor generalization on new, unseen data. It often results from models being too complex relative to the amount of training data. To address overfitting, techniques such as regularization, reducing model complexity, increasing the size of the training dataset, and using cross-validation to evaluate model performance on different subsets of data can be employed\",\n",
    "        \"Cross-validation is a technique used to assess a model's performance by partitioning the dataset into multiple subsets. The model is trained on some subsets and tested on others, allowing for a more robust evaluation. Common methods include k-fold cross-validation, where the data is divided into k subsets, and the model is trained and tested k times, each time using a different subset for testing.\",\n",
    "        \"The bias-variance tradeoff is a fundamental concept in machine learning that deals with finding the right level of model complexity. High bias (underfitting) occurs when a model is too simple and cannot capture the underlying patterns in the data. High variance (overfitting) occurs when a model is too complex and fits the training data too closely, failing to generalize well to new data. Balancing bias and variance is crucial for building models that perform well on diverse datasets. Regularization techniques and model selection are commonly used to manage the bias-variance tradeoff\"\n",
    "    ]\n",
    "\n",
    "    return extract_keywords(correct_answers[chosen_index])\n",
    "\n",
    "# Example usage\n",
    "chosen_number = 1  # Assuming the student picked 1\n",
    "paths = r\"D:\\AI_interview\\recorded\\answer_1.wav\"\n",
    "score = evaluate_student_answer(paths, chosen_number)\n",
    "print(f\"Final Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ad6cd-4009-497f-92a9-b58968213712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
